# 文本特徵工程

## 可以嘗試的文本特徵

詞層級
- N-gram
- 分詞
- 短語抽取
- 實體
- 事件觸發詞

句層級
- 事件三元組
- 聚合句子向量
- 句子向量列表

文章層級
- 整個文章向量

## 詞層級

- input: 同個時段之文章標題

- functions
![](https://i.imgur.com/yiWzWs4.png)

### 分詞

詞彙矩陣本身就很稀疏

![](https://i.imgur.com/iPq2d9W.png)

經標準化後跑 PCA 的解釋性不好，遂不用來繼續跑預測

![](https://i.imgur.com/y5cTqE3.png)

### N-gram

一次用 2-6 個字元下去組會導致 kernel 掛掉、不管是 notebook or terminal 都測試過

![](https://i.imgur.com/MulmbMs.png)

改成先跑 `ngram_range=(2,2)`



---

- check each notebook performence of en datasets
- (zh) try `CountVectorizer(n_gram=(2,2))`/keyphrase/sentence clustering
- (zh) use CNYES (當成擴充GOODINFO)
  - count stock contains distribution
- (zh) 回去檢查三元組生成的位置問題
- fix kgbuilder output format
- learn data columns from two sigma

---

* Single-Language BERT 表現較優、又以中文全詞遮罩最優
  * https://github.com/google-research/bert/blob/master/multilingual.md
  * https://github.com/ymcui/Chinese-BERT-wwm/blob/master/README_EN.md
* Ray, Zero-shot 測試 from 英文新聞到中文新聞, Siameas BERT 
