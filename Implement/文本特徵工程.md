# 文本特徵工程

## 可以嘗試的文本特徵

詞層級
- N-gram
- 分詞
- 短語抽取
- 實體
- 事件觸發詞

句層級
- 事件三元組
- 聚合句子向量
- 句子向量列表

文章層級
- 整個文章向量

## 詞層級

- input: 同個時段之文章標題

- functions
![](https://i.imgur.com/yiWzWs4.png)

### 分詞

詞彙矩陣本身就很稀疏

![](https://i.imgur.com/iPq2d9W.png)

經標準化後跑 PCA 的解釋性不好，遂不用來繼續跑預測

![](https://i.imgur.com/y5cTqE3.png)

### N-gram

---

* Ocotparse 變得很奇怪 有時候會爬很慢或到一個數量自己停止 文本蒐集這樣真的很不好做 我也希望我可以直接用數值型就沒這些問題了
* Single-Language BERT 表現較優、又以中文全詞遮罩最優
  * https://github.com/google-research/bert/blob/master/multilingual.md
  * https://github.com/ymcui/Chinese-BERT-wwm/blob/master/README_EN.md
* Ray, Zero-shot 測試 from 英文新聞到中文新聞, Siameas BERT 

